{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd \nimport cv2\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Input, Conv2DTranspose, Cropping2D\nimport keras.utils.all_utils as kr_utils\nimport keras.regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T21:09:17.78258Z","iopub.execute_input":"2022-04-25T21:09:17.782946Z","iopub.status.idle":"2022-04-25T21:09:24.297968Z","shell.execute_reply.started":"2022-04-25T21:09:17.78286Z","shell.execute_reply":"2022-04-25T21:09:24.297148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnp.random.seed = 24\nimgdir = '../input/img-data/images/images'\nmaskdir = '../input/img-data/masks/masks'\nimgs = []\nmasks = []\n\nfor filename in os.listdir(imgdir):\n    imgpath = os.path.join(imgdir, filename)\n    maskpath = os.path.join(maskdir, filename)\n    imginst = cv2.imread(imgpath)\n    maskinst = cv2.imread(maskpath)\n    \n    imginst = cv2.cvtColor(imginst, cv2.COLOR_BGR2RGB)\n    imgind = np.nonzero(maskinst > 0)\n    maskinst[imgind[0],imgind[1],:] = 255\n    \n    imgs.append(imginst)\n    masks.append(maskinst)\n\nmasks = np.array(masks)\nmasks = masks[:,:,:,0]\nmasks = np.expand_dims(masks,3)\n#print(np.unique(masks))\n#print(masks.shape)\nimgs = np.array(imgs)\nplt.imshow(masks[6])\nplt.plot()\nX_train, X_test, y_train, y_test = train_test_split(imgs,masks,test_size = 1/10, random_state = 24)    ","metadata":{"execution":{"iopub.status.busy":"2022-04-25T21:09:24.29971Z","iopub.execute_input":"2022-04-25T21:09:24.299946Z","iopub.status.idle":"2022-04-25T21:09:29.937503Z","shell.execute_reply.started":"2022-04-25T21:09:24.299914Z","shell.execute_reply":"2022-04-25T21:09:29.936855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_ratio = 8/100\nmax_conv_maps = 256\n\ndef encoders(mod_input, conv_maps, filter_sz, padding_type):\n    ei = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(mod_input)\n    ei = Dropout(drop_ratio)(ei)\n    ei = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(ei)\n    return ei\n\ndef decoders(enc_input, up_input, up_maps, up_sz, up_stride, padding_type, conv_maps, filter_sz, Print = False):\n    up_do = Conv2DTranspose(up_maps, up_sz, strides=up_stride, padding = padding_type)(up_input)\n    if (Print):\n        print(up_do.shape)\n    up_do = Concatenate()([enc_input,up_do])\n    up_do = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(up_do)\n    up_do = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(up_do)\n    return up_do\n\ncnn_input = Input(shape=(360, 480, 3))\neo1 = encoders(cnn_input, max_conv_maps / (2 ** 4), (3,3), 'same')\n#crp1 = Cropping2D(((4,4),(0,0)))(eo1)\n#print(eo1.shape)\n#print(crp1.shape)\nei2 = MaxPooling2D((2,2))(eo1)\n\neo2 = encoders(ei2, max_conv_maps / (2 ** 3), (3,3), 'same')\n#crp2 = Cropping2D(((2,2),(0,0)))(eo2)\n#print(eo2.shape)\n#print(crp2.shape)\nei3 = MaxPooling2D((2,2))(eo2)\n\neo3 = encoders(ei3, max_conv_maps / (2 ** 2), (3,3), 'same')\n#crp3 = Cropping2D(((1,1),(0,0)))(eo3)\n#print(eo3.shape)\n#print(crp3.shape)\nei4 = MaxPooling2D((2,2))(eo3)\n\neo4 = encoders(ei4, max_conv_maps / (2 ** 1), (3,3), 'same')\n#crp4 = Cropping2D(((1,0),(0,0)))(eo4)\n#print(eo4.shape)\n#print(crp4.shape)\nei5 = MaxPooling2D((3,3))(eo4)\n\npeak = Conv2D(max_conv_maps / (2 ** 0),(3,3),padding = 'same', activation='relu')(ei5)\npeak = Dropout(drop_ratio)(peak)\npeak = Conv2D(max_conv_maps / (2 ** 0),(3,3),padding = 'same', activation='relu')(peak)\n\ndo4 = decoders(eo4, peak, max_conv_maps / (2 ** 1), (3,3), (3,3), 'same', 128, (3,3))\ndo3 = decoders(eo3, do4, max_conv_maps / (2 ** 2), (2,2), (2,2), 'same', 64, (3,3))\ndo2 = decoders(eo2, do3, max_conv_maps / (2 ** 3), (2,2), (2,2), 'same', 32, (3,3))\ndo1 = decoders(eo1, do2, max_conv_maps / (2 ** 4), (2,2), (2,2), 'same', 16, (3,3))\n\nfin_out = Conv2D(1, (1,1), padding = 'same', activation='sigmoid')(do1)\n\nmodel = Model(inputs = cnn_input, outputs = fin_out)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T21:09:29.93868Z","iopub.execute_input":"2022-04-25T21:09:29.938915Z","iopub.status.idle":"2022-04-25T21:09:32.780906Z","shell.execute_reply.started":"2022-04-25T21:09:29.938882Z","shell.execute_reply":"2022-04-25T21:09:32.780132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callbk = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model\", # name of file to save the best model to\n    monitor=\"val_accuracy\", # prefix val to specify that we want the model with best macroF1 on the validation data\n    verbose=1, # prints out when the model achieve a better epoch\n    mode=\"max\", # the monitored metric should be maximized\n    save_freq=\"epoch\", # clear\n    save_best_only=True, # of course, if not, every time a new best is achieved will be savedf differently\n    save_weights_only=True # this means that we don't have to save the architecture, if you change the architecture, you'll loose the old weights\n)\nkf = KFold(n_splits = 7, shuffle = True, random_state = 24)\n\nfor trainind, testind in kf.split(X_train,y_train):\n    model.fit(x = X_train[trainind,:,:,:], y = y_train[trainind], validation_data = (X_train[testind,:,:,:], y_train[testind]), callbacks=[checkpoint_callbk], epochs=10,\n    batch_size=5, verbose=0)\nmodel.load_weights(\"best_model\")","metadata":{"execution":{"iopub.status.busy":"2022-04-25T21:09:32.785867Z","iopub.execute_input":"2022-04-25T21:09:32.786672Z","iopub.status.idle":"2022-04-25T21:12:14.121166Z","shell.execute_reply.started":"2022-04-25T21:09:32.786627Z","shell.execute_reply":"2022-04-25T21:12:14.120367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T21:12:14.122329Z","iopub.execute_input":"2022-04-25T21:12:14.122614Z","iopub.status.idle":"2022-04-25T21:12:16.719161Z","shell.execute_reply.started":"2022-04-25T21:12:14.122579Z","shell.execute_reply":"2022-04-25T21:12:16.71848Z"},"trusted":true},"execution_count":null,"outputs":[]}]}