{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd \nimport cv2\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Input, Conv2DTranspose, Cropping2D\nimport keras.utils.all_utils as kr_utils\nimport keras.regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import MeanShift\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T18:33:59.975092Z","iopub.execute_input":"2022-04-29T18:33:59.975822Z","iopub.status.idle":"2022-04-29T18:34:06.340026Z","shell.execute_reply.started":"2022-04-29T18:33:59.97573Z","shell.execute_reply":"2022-04-29T18:34:06.339282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnp.random.seed = 24\nimgdir_train = '../input/traindata/images'\nmaskdir_train = '../input/traindata/masks'\nimgdir_test = '../input/testdata/images'\nmaskdir_test = '../input/testdata/masks'\nimgs = []\nmasks = []\nnames = []\n\ndef extractxy(imgdir, maskdir, showimgs = False):\n\n    imgs = []\n    masks = []\n    names = []\n    \n    for filename in os.listdir(imgdir):\n        names.append(filename)\n        imgpath = os.path.join(imgdir, filename)\n        maskpath = os.path.join(maskdir, filename)\n        imginst = cv2.imread(imgpath)\n        maskinst = cv2.imread(maskpath)\n\n        imginst = cv2.cvtColor(imginst, cv2.COLOR_BGR2RGB)\n        imgind = np.nonzero(maskinst > 0)\n        maskinst[imgind[0],imgind[1],:] = 1\n\n        imgs.append(imginst)\n        masks.append(maskinst)\n        \n    masks = np.array(masks)\n    masks = masks[:,:,:,0]\n    masks = np.expand_dims(masks,3)\n    imgs = np.array(imgs)\n    if showimgs:\n        for i in range(masks.shape[0]):\n            fig, axs = plt.subplots(1,2)\n            #print(names[i])\n            axs[0].imshow(masks[i])\n            axs[0].set_title(names[i])\n            axs[1].imshow(imgs[i])\n            axs[1].set_title(names[i])\n            plt.plot()\n    \n    return imgs, masks\n\n#scaler = MinMaxScaler()\nX_train, y_train = extractxy(imgdir_train, maskdir_train)\nX_train = X_train / 255\n#scaler.fit_transform(X_train[])\nX_test, y_test = extractxy(imgdir_test, maskdir_test, True)\nX_test = X_test / 255\n#scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:34:06.341777Z","iopub.execute_input":"2022-04-29T18:34:06.342014Z","iopub.status.idle":"2022-04-29T18:34:23.986642Z","shell.execute_reply.started":"2022-04-29T18:34:06.341982Z","shell.execute_reply":"2022-04-29T18:34:23.985861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_ratio = 8/100\nmax_conv_maps = 256\n\ndef encoders(mod_input, conv_maps, filter_sz, padding_type):\n    ei = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(mod_input)\n    ei = Dropout(drop_ratio)(ei)\n    ei = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(ei)\n    return ei\n\ndef decoders(enc_input, up_input, up_maps, up_sz, up_stride, padding_type, conv_maps, filter_sz, Print = False):\n    up_do = Conv2DTranspose(up_maps, up_sz, strides=up_stride, padding = padding_type)(up_input)\n    if (Print):\n        print(up_do.shape)\n    up_do = Concatenate()([enc_input,up_do])\n    up_do = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(up_do)\n    up_do = Conv2D(conv_maps,filter_sz,padding = padding_type, activation='relu')(up_do)\n    return up_do\n\ncnn_input = Input(shape=(360, 480, 3))\neo1 = encoders(cnn_input, max_conv_maps / (2 ** 4), (3,3), 'same')\n#crp1 = Cropping2D(((4,4),(0,0)))(eo1)\n#print(eo1.shape)\n#print(crp1.shape)\nei2 = MaxPooling2D((2,2))(eo1)\n\neo2 = encoders(ei2, max_conv_maps / (2 ** 3), (3,3), 'same')\n#crp2 = Cropping2D(((2,2),(0,0)))(eo2)\n#print(eo2.shape)\n#print(crp2.shape)\nei3 = MaxPooling2D((2,2))(eo2)\n\neo3 = encoders(ei3, max_conv_maps / (2 ** 2), (3,3), 'same')\n#crp3 = Cropping2D(((1,1),(0,0)))(eo3)\n#print(eo3.shape)\n#print(crp3.shape)\nei4 = MaxPooling2D((2,2))(eo3)\n\neo4 = encoders(ei4, max_conv_maps / (2 ** 1), (3,3), 'same')\n#crp4 = Cropping2D(((1,0),(0,0)))(eo4)\n#print(eo4.shape)\n#print(crp4.shape)\nei5 = MaxPooling2D((3,3))(eo4)\n\npeak = Conv2D(max_conv_maps / (2 ** 0),(3,3),padding = 'same', activation='relu')(ei5)\npeak = Dropout(drop_ratio)(peak)\npeak = Conv2D(max_conv_maps / (2 ** 0),(3,3),padding = 'same', activation='relu')(peak)\n\ndo4 = decoders(eo4, peak, max_conv_maps / (2 ** 1), (3,3), (3,3), 'same', 128, (3,3))\ndo3 = decoders(eo3, do4, max_conv_maps / (2 ** 2), (2,2), (2,2), 'same', 64, (3,3))\ndo2 = decoders(eo2, do3, max_conv_maps / (2 ** 3), (2,2), (2,2), 'same', 32, (3,3))\ndo1 = decoders(eo1, do2, max_conv_maps / (2 ** 4), (2,2), (2,2), 'same', 16, (3,3))\n\nfin_out = Conv2D(1, (1,1), padding = 'same', activation='sigmoid')(do1)\n\nmodel = Model(inputs = cnn_input, outputs = fin_out)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:34:23.988059Z","iopub.execute_input":"2022-04-29T18:34:23.988441Z","iopub.status.idle":"2022-04-29T18:34:26.49701Z","shell.execute_reply.started":"2022-04-29T18:34:23.988406Z","shell.execute_reply":"2022-04-29T18:34:26.496317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callbk = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model\", # name of file to save the best model to\n    monitor=\"val_accuracy\", # prefix val to specify that we want the model with best macroF1 on the validation data\n    verbose=1, # prints out when the model achieve a better epoch\n    mode=\"max\", # the monitored metric should be maximized\n    save_freq=\"epoch\", # clear\n    save_best_only=True, # of course, if not, every time a new best is achieved will be savedf differently\n    save_weights_only=True # this means that we don't have to save the architecture, if you change the architecture, you'll loose the old weights\n)\nkf = KFold(n_splits = 4, shuffle = True, random_state = 24)\n\nfor trainind, testind in kf.split(X_train,y_train):\n    model.fit(x = X_train[trainind,:,:,:], y = y_train[trainind], validation_data = (X_train[testind,:,:,:], y_train[testind]), callbacks=[checkpoint_callbk], epochs=10,\n    batch_size=5, verbose=0)\nmodel.load_weights(\"best_model\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:34:26.498519Z","iopub.execute_input":"2022-04-29T18:34:26.498758Z","iopub.status.idle":"2022-04-29T18:36:00.827773Z","shell.execute_reply.started":"2022-04-29T18:34:26.498726Z","shell.execute_reply":"2022-04-29T18:36:00.827112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test, verbose = 1)\npred = model.predict(X_test)\npred[pred > (1/2)] = 255\npred[pred <= (1/2)] = 0\nprint(np.unique(y_test))\npic_ious = []\npic_fdr = []\npic_precision = []\npic_recall = []\niou_zeros = 0\nzero_pos = 0\nfor samp in zip(pred[:,:,:,0], y_test[:,:,:,0]):\n    ind_pred = np.nonzero(samp[0] > 0)\n    indx_pred = ind_pred[0]\n    indy_pred = ind_pred[1]\n    ind_pred = np.column_stack((indx_pred,indy_pred))\n    pred_pos = ind_pred.shape[0]\n    \n    ind_test = np.nonzero(samp[1] > 0)\n    indx_test = ind_test[0]\n    indy_test = ind_test[1]\n    ind_test = np.column_stack((indx_test,indy_test))\n    pos = ind_test.shape[0]\n    \n    coord_all = np.concatenate((ind_test,ind_pred), axis = 0)\n    ind_test = set([tuple(ele) for ele in ind_test])\n    ind_pred = set([tuple(ele) for ele in ind_test])\n    coord_unique = set(tuple(row) for row in coord_all)\n    intersect = np.array([val for val in ind_test & ind_pred]) \n    true_pos = intersect.shape[0]\n    false_pos = pred_pos - true_pos\n    \n    if (pos) != 0:\n        recall = true_pos / (pos) # false discorvery rate\n    else:\n        recall = 0\n    \n    pic_recall.append(recall)\n    \n    if (false_pos + true_pos) != 0:\n        precision = true_pos / (false_pos + true_pos) # false discorvery rate\n    else:\n        precision = 0\n        \n    pic_precision.append(precision)\n    # false_pos / (pos)\n    if (false_pos + true_pos) != 0:\n        fdr = false_pos / (false_pos + true_pos) # false discorvery rate\n    else:\n        zero_pos += 0\n        fdr = 0\n        \n    pic_fdr.append(fdr)\n        \n    if len(coord_unique) > 0:\n        iou = (true_pos) / (len(coord_unique))\n    else:\n        iou_zeros += 1\n        iou = 0\n    pic_ious.append(iou)\n    #print(len(coord_unique))\n    #print(intersect.shape[0])\n    #print(f'IOU = {iou}')\n    #print('-------------------')\n\npic_fdr = np.array(pic_fdr)\nprint(f'Mean FDR = {np.mean(pic_fdr)}')\nprint(f'Proportion of zero positives = {zero_pos / pic_fdr.shape[0]}')\n    \npic_ious = np.array(pic_ious)\nprint(f'Mean IOU = {np.mean(pic_ious)}')\nprint(f'Proportion of intersection zeros = {iou_zeros / pic_ious.shape[0]}')\nprint(pic_recall)\nprint(pic_precision)\nplt.scatter(pic_recall,pic_precision)\n#fig, axs = plt.subplots(1,1)\n#axs.plot(recall,precision)\n'''\nfig, axs = plt.subplots(1,3)\nimgnum = 17\n#pred[imgnum,20:90,20:90,0] = 255 \nind = np.nonzero(pred[imgnum,:,:,0] > 0)\ntemparr = np.zeros((360,480,1))\ntemparr[ind[0],ind[1],:] = 255\naxs[0].imshow(temparr)\naxs[1].imshow(y_test[imgnum])\naxs[2].imshow(X_test[imgnum])\n#360 by 480\ntemparr = np.reshape(temparr,(360,480))\n#dcluster = KMeans(1).fit(temparr)\ndcluster = DBSCAN(min_samples = 200).fit(temparr)\nprint(np.unique(dcluster.labels_))\nclusterind = np.nonzero(dcluster.labels_ == 0)[0]\nA = ind[0][clusterind]\nB = ind[1][clusterind]\ntemparr2 = np.zeros((360,480,1))\ntemparr2[A,B,:] = 255\naxs[2].imshow(temparr2)\nplt.plot()\n'''","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:36:00.8298Z","iopub.execute_input":"2022-04-29T18:36:00.830063Z","iopub.status.idle":"2022-04-29T18:36:07.73795Z","shell.execute_reply.started":"2022-04-29T18:36:00.830028Z","shell.execute_reply":"2022-04-29T18:36:07.737154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\ny_true = np.array([[0, 1, 1],[1, 1, 0]])\ny_pred = np.array([[0, 1, 1],[1, 0, 0]])\n\ndum1 = np.array([1,2,3,4])\ndum2 = np.array([1,2,3,4])\ndum3 = np.column_stack((dum1,dum2))\nprint(dum3)\n\narr1 = np.concatenate((y_true,y_pred), axis = 0)\nprint(arr1)\n\nuniqarr = np.array(list(set(tuple(row) for row in arr1)))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:36:07.739182Z","iopub.execute_input":"2022-04-29T18:36:07.739449Z","iopub.status.idle":"2022-04-29T18:36:07.748777Z","shell.execute_reply.started":"2022-04-29T18:36:07.739414Z","shell.execute_reply":"2022-04-29T18:36:07.748003Z"},"trusted":true},"execution_count":null,"outputs":[]}]}